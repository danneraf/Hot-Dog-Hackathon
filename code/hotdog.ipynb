{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5932c3b0-2e22-4cb8-a06c-a1a553bd835b",
   "metadata": {},
   "source": [
    "# <img src=\"https://img.buzzfeed.com/buzzfeed-static/static/2017-07/11/14/asset/buzzfeed-prod-fastlane-01/sub-buzz-6725-1499796406-2.png\" width=\"55\" height=\"55\"> Hot dog?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5778784-a413-406a-a44f-0eab6dad4ae5",
   "metadata": {},
   "source": [
    "[Data](https://www.kaggle.com/datasets/yashvrdnjain/hotdognothotdog/code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3534dc5-48fd-459d-a340-5e9d1f19e9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 15:41:15.508095: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#https://www.geeksforgeeks.org/how-to-iterate-through-images-in-a-folder-python/\n",
    "import os\n",
    "\n",
    "# I'm tired of unnecessary warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Tensorflow will not let me silence it :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34d0168-6584-4471-804a-097677cdc9c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Data and Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ff08826-e082-431c-8c0f-6d661f66fbf0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 validated image filenames belonging to 2 classes.\n",
      "Found 644 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 15:41:19.231854: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - ETA: 0s - loss: 0.6849 - accuracy: 0.5497"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 15:41:32.037745: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 15s 149ms/step - loss: 0.6849 - accuracy: 0.5497 - val_loss: 0.6632 - val_accuracy: 0.6056\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 14s 149ms/step - loss: 0.6625 - accuracy: 0.6193 - val_loss: 0.6631 - val_accuracy: 0.6102\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 14s 144ms/step - loss: 0.6371 - accuracy: 0.6423 - val_loss: 0.6483 - val_accuracy: 0.6304\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 14s 150ms/step - loss: 0.6301 - accuracy: 0.6570 - val_loss: 0.6398 - val_accuracy: 0.6242\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 14s 146ms/step - loss: 0.6000 - accuracy: 0.6853 - val_loss: 0.6313 - val_accuracy: 0.6584\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 16s 166ms/step - loss: 0.6006 - accuracy: 0.6893 - val_loss: 0.6204 - val_accuracy: 0.6630\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 15s 155ms/step - loss: 0.5898 - accuracy: 0.6920 - val_loss: 0.6330 - val_accuracy: 0.6242\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 14s 154ms/step - loss: 0.5849 - accuracy: 0.6930 - val_loss: 0.6014 - val_accuracy: 0.6755\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 14s 148ms/step - loss: 0.5875 - accuracy: 0.6913 - val_loss: 0.5812 - val_accuracy: 0.7065\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 13s 143ms/step - loss: 0.5581 - accuracy: 0.7117 - val_loss: 0.6008 - val_accuracy: 0.6801\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 13s 141ms/step - loss: 0.5526 - accuracy: 0.7233 - val_loss: 0.5646 - val_accuracy: 0.7174\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 14s 148ms/step - loss: 0.5402 - accuracy: 0.7393 - val_loss: 0.5648 - val_accuracy: 0.7003\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 14s 150ms/step - loss: 0.5407 - accuracy: 0.7260 - val_loss: 0.5964 - val_accuracy: 0.6693\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 13s 135ms/step - loss: 0.5410 - accuracy: 0.7290 - val_loss: 0.5901 - val_accuracy: 0.7081\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 14s 148ms/step - loss: 0.5250 - accuracy: 0.7470 - val_loss: 0.5559 - val_accuracy: 0.7174\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 13s 143ms/step - loss: 0.5325 - accuracy: 0.7300 - val_loss: 0.5915 - val_accuracy: 0.6957\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 14s 152ms/step - loss: 0.5200 - accuracy: 0.7493 - val_loss: 0.5695 - val_accuracy: 0.7003\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 15s 158ms/step - loss: 0.5170 - accuracy: 0.7493 - val_loss: 0.5570 - val_accuracy: 0.7050\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 14s 151ms/step - loss: 0.5099 - accuracy: 0.7563 - val_loss: 0.5859 - val_accuracy: 0.7096\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 14s 144ms/step - loss: 0.4990 - accuracy: 0.7553 - val_loss: 0.5555 - val_accuracy: 0.7174\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 14s 154ms/step - loss: 0.4938 - accuracy: 0.7557 - val_loss: 0.5989 - val_accuracy: 0.7034\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 14s 149ms/step - loss: 0.5024 - accuracy: 0.7447 - val_loss: 0.5498 - val_accuracy: 0.7096\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 15s 160ms/step - loss: 0.4905 - accuracy: 0.7697 - val_loss: 0.5538 - val_accuracy: 0.7236\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 13s 140ms/step - loss: 0.4886 - accuracy: 0.7620 - val_loss: 0.5812 - val_accuracy: 0.7143\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 15s 159ms/step - loss: 0.4964 - accuracy: 0.7507 - val_loss: 0.5561 - val_accuracy: 0.7127\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 14s 147ms/step - loss: 0.4813 - accuracy: 0.7687 - val_loss: 0.5668 - val_accuracy: 0.7205\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 14s 147ms/step - loss: 0.4726 - accuracy: 0.7813 - val_loss: 0.5718 - val_accuracy: 0.7283\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 20s 212ms/step - loss: 0.4724 - accuracy: 0.7673 - val_loss: 0.5462 - val_accuracy: 0.7050\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 16s 165ms/step - loss: 0.4735 - accuracy: 0.7663 - val_loss: 0.6207 - val_accuracy: 0.7174\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 16s 176ms/step - loss: 0.4686 - accuracy: 0.7747 - val_loss: 0.5571 - val_accuracy: 0.7205\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 14s 143ms/step - loss: 0.4779 - accuracy: 0.7757 - val_loss: 0.5650 - val_accuracy: 0.7174\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 14s 145ms/step - loss: 0.4605 - accuracy: 0.7800 - val_loss: 0.5609 - val_accuracy: 0.7220\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 18s 190ms/step - loss: 0.4550 - accuracy: 0.7840 - val_loss: 0.5907 - val_accuracy: 0.7205\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 15s 156ms/step - loss: 0.4611 - accuracy: 0.7807 - val_loss: 0.5466 - val_accuracy: 0.7376\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 12s 128ms/step - loss: 0.4811 - accuracy: 0.7730 - val_loss: 0.5584 - val_accuracy: 0.7220\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 13s 138ms/step - loss: 0.4414 - accuracy: 0.7930 - val_loss: 0.5574 - val_accuracy: 0.7298\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 12s 131ms/step - loss: 0.4546 - accuracy: 0.7883 - val_loss: 0.5691 - val_accuracy: 0.7298\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 14s 154ms/step - loss: 0.4401 - accuracy: 0.7917 - val_loss: 0.5766 - val_accuracy: 0.7127\n"
     ]
    }
   ],
   "source": [
    "# Define the paths to the directories\n",
    "train_hot_path = '../train_hotdog'\n",
    "train_nothot_path = '../train_nothotdog'\n",
    "test_hot_path = '../test_hotdog'\n",
    "test_nothot_path = '../test_nothotdog'\n",
    "\n",
    "# Iterate over the images within the train hotdog folder\n",
    "train_hotdog_images = []\n",
    "for file in os.listdir(train_hot_path):\n",
    "    if file.endswith('.jpg'):\n",
    "        image_path = os.path.join(train_hot_path, file)\n",
    "        train_hotdog_images.append(image_path)\n",
    "\n",
    "# Iterate over the images within the train not hotdog folder\n",
    "train_nothotdog_images = []\n",
    "for file in os.listdir(train_nothot_path):\n",
    "    if file.endswith('.jpg'):\n",
    "        image_path = os.path.join(train_nothot_path, file)\n",
    "        train_nothotdog_images.append(image_path)\n",
    "\n",
    "# Iterate over the images within the test hotdog folder\n",
    "test_hotdog_images = []\n",
    "for file in os.listdir(test_hot_path):\n",
    "    if file.endswith('.jpg'):\n",
    "        image_path = os.path.join(test_hot_path, file)\n",
    "        test_hotdog_images.append(image_path)\n",
    "\n",
    "# Iterate over the images within the test not hotdog folder\n",
    "test_nothotdog_images = []\n",
    "for file in os.listdir(test_nothot_path):\n",
    "    if file.endswith('.jpg'):\n",
    "        image_path = os.path.join(test_nothot_path, file)\n",
    "        test_nothotdog_images.append(image_path)\n",
    "\n",
    "# Create the train_data DataFrame\n",
    "train_data = pd.DataFrame({\n",
    "    'image_path': train_hotdog_images + train_nothotdog_images,\n",
    "    'label': ['hot dog'] * len(train_hotdog_images) + ['not hot dog'] * len(train_nothotdog_images)\n",
    "})\n",
    "\n",
    "# Create the test_data DataFrame\n",
    "test_data = pd.DataFrame({\n",
    "    'image_path': test_hotdog_images + test_nothotdog_images,\n",
    "    'label': ['hot dog'] * len(test_hotdog_images) + ['not hot dog'] * len(test_nothotdog_images)\n",
    "})\n",
    "\n",
    "# ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    train_data,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=(28, 28),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(\n",
    "    test_data,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=(28, 28),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Build and train the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu')) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu')) \n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Train the model with EarlyStopping\n",
    "history = model.fit(train_generator, epochs=100, batch_size=64, validation_data=test_generator, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35af326d-082a-4694-8607-2b6771f90eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 15:50:27.264486: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5759133100509644\n",
      "Test Accuracy: 0.7251552939414978\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate_generator(test_generator)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0646b53-7d7c-4c26-ac92-bfb5ed4d85eb",
   "metadata": {},
   "source": [
    "Not the best, but decent - the high loss is concerning, but I am happy the accuracy is above 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9691e27-f22a-4c9e-b610-d1dd4ce97e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Calculate the baseline accuracy\n",
    "baseline_accuracy = test_generator.labels.count(0) / len(test_generator.labels)\n",
    "\n",
    "# Print the baseline accuracy\n",
    "print('Baseline Accuracy:', baseline_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f362ae80-1cf1-466f-8460-92d8691e3369",
   "metadata": {},
   "source": [
    "The CNN model works better than the baseline, predicting roughly 20% more accurately than baseline. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63152bb5-fea2-4cc4-80f6-7e30da7f1a71",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fdd3110-b42a-4985-be26-b2b51bc97192",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4506e5-3326-499b-91c0-eea5007daf03",
   "metadata": {},
   "source": [
    "# <img src=\"https://img.buzzfeed.com/buzzfeed-static/static/2017-07/11/5/campaign_images/buzzfeed-prod-fastlane-02/people-are-dying-laughing-at-snapchats-new-hot-do-2-23226-1499766389-1_dblbig.jpg?resize=1200:*\" width=\"300\" height=\"200\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
